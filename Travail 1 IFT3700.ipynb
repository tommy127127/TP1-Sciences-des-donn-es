{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# David Ogaus, Jonathan Caspar, Tommy Côté et Xiuli Zhang \n",
    "## IFT 3700\n",
    "## 6 Novembre 2018\n",
    "## Travail 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure de similarité\n",
    "ON va mettre ici notre description de la mesure de similarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La métrique euclidienne\n",
    "def metric_euclid(x, y):\n",
    "    sum=0\n",
    "    for i in range(len(x)):\n",
    "        sum += (x[i]-y[i])**2\n",
    "    return math.sqrt(sum)\n",
    "\n",
    "# La métrique #1 dans le fichier word\n",
    "def metric_n1(x, y):\n",
    "    sum_x=0\n",
    "    sum_y=0\n",
    "    for i in range(len(x)):\n",
    "        sum_x += x[i]\n",
    "        sum_y += y[i]\n",
    "    return abs(sum_x - sum_y)\n",
    "\n",
    "# La métrique #3 dans le fichier word\n",
    "def metric_n3(x, y):\n",
    "    sum=0\n",
    "    for i in range(len(x)):\n",
    "        if ((x[i]==0 and y[i]==0) or (x[i]!=0 and y[i]!=0)):\n",
    "            sum+=1\n",
    "    return 1 - sum/784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation du jeu de données MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#On ouvre le fichier 'mnist_train.csv'\n",
    "data = open('e:\\ift3700\\mnist_train.csv')\n",
    "csv_file = csv.reader(data)\n",
    "data_points = []\n",
    "for row in csv_file:\n",
    "    data_points.append(row)\n",
    "data.close()\n",
    "\n",
    "#On enlève la première ligne, soit les \"headers\" de nos colonnes\n",
    "data_points.pop(0)\n",
    "\n",
    "#On transforme les données en integers\n",
    "for i in range(len(data_points)):\n",
    "    for j in range(0,785):\n",
    "            data_points[i][j] = int(data_points[i][j])\n",
    "\n",
    "#Vecteur 60 000 x 1 qui contient les étiquettes\n",
    "y_train = []\n",
    "for row in data_points:\n",
    "    y_train.append(row[0])\n",
    "\n",
    "#Matrice 60 000 x 784 qui contient les données\n",
    "x_train = []\n",
    "for row in data_points:\n",
    "    x_train.append(row[1:785])\n",
    "\n",
    "    \n",
    "#On ouvre le fichier 'mnist_test.csv'\n",
    "data = open('e:\\ift3700\\mnist_test.csv')\n",
    "csv_file = csv.reader(data)\n",
    "data_points = []\n",
    "for row in csv_file:\n",
    "    data_points.append(row)\n",
    "data.close()\n",
    "\n",
    "#On enlève la première ligne, soit les \"headers\" de nos colones\n",
    "data_points.pop(0)\n",
    "\n",
    "#Convertir en int\n",
    "for i in range(len(data_points)):\n",
    "    for j in range(0,785):\n",
    "            data_points[i][j] = int(data_points[i][j])\n",
    "\n",
    "#Vecteur 10 000 x 1 qui contient les étiquettes\n",
    "y_test = []\n",
    "for row in data_points:\n",
    "    y_test.append(row[0])\n",
    "\n",
    "#Matrice 10 000 x 784 qui contient les données\n",
    "x_test = []\n",
    "for row in data_points:\n",
    "    x_test.append(row[1:785])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme k-moyenne\n",
    "On utilise un algorithme **k_medoid** (crédit à https://github.com/salspaugh/machine_learning/blob/master/clustering/kmedoids.py) pour pouvoir utiliser une distance personalisée grâce à des matrices de distance (ce qui n'est pas possible avec la version KMeans de sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_medoid(distances, k=10):\n",
    "\n",
    "    m = distances.shape[0] # number of points\n",
    "\n",
    "    # Pick k random medoids.\n",
    "    curr_medoids = np.array([-1]*k)\n",
    "    while not len(np.unique(curr_medoids)) == k:\n",
    "        curr_medoids = np.array([random.randint(0, m - 1) for _ in range(k)])\n",
    "    old_medoids = np.array([-1]*k) # Doesn't matter what we initialize these to.\n",
    "    new_medoids = np.array([-1]*k)\n",
    "\n",
    "    # Until the medoids stop updating, do the following:\n",
    "    while not ((old_medoids == curr_medoids).all()):\n",
    "        # Assign each point to cluster with closest medoid.\n",
    "        clusters = assign_points_to_clusters(curr_medoids, distances)\n",
    "\n",
    "        # Update cluster medoids to be lowest cost point.\n",
    "        for curr_medoid in curr_medoids:\n",
    "            cluster = np.where(clusters == curr_medoid)[0]\n",
    "            new_medoids[curr_medoids == curr_medoid] = compute_new_medoid(cluster, distances)\n",
    "\n",
    "        old_medoids[:] = curr_medoids[:]\n",
    "        curr_medoids[:] = new_medoids[:]\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def assign_points_to_clusters(medoids, distances):\n",
    "    distances_to_medoids = distances[:,medoids]\n",
    "    clusters = medoids[np.argmin(distances_to_medoids, axis=1)]\n",
    "    assert (clusters[medoids] == medoids).all()\n",
    "    return clusters\n",
    "    \n",
    "def compute_new_medoid(cluster, distances):\n",
    "    mask = np.ones(distances.shape)\n",
    "    mask[np.ix_(cluster,cluster)] = 0.\n",
    "    cluster_distances = np.ma.masked_array(data=distances, mask=mask, fill_value=10e9)\n",
    "    costs = cluster_distances.sum(axis=1)\n",
    "    return costs.argmin(axis=0, fill_value=10e9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule la matrice de distance euclidienne et n3. \n",
    "Puis on compare le score silhouette obtenu pour différent k en utilisant **KMeans** de sklearn et **k-medoid** (euclidien et distance n3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble de donné réduit pour faire des tests\n",
    "x__test= x_test[0:500]\n",
    "\n",
    "# Définie une matrice des distances avec la métrique de notre choix\n",
    "m_eucli = pairwise_distances(x__test, metric='euclidean')\n",
    "m_n3 = pairwise_distances(x__test, metric=metric_n3)\n",
    "\n",
    "scores = []\n",
    "scores_t=[]\n",
    "scores_n3=[]\n",
    "k_range = range(2,15)\n",
    "for k in k_range:\n",
    "    y_pred = KMeans(n_clusters=k).fit_predict(x__test)\n",
    "    scores.append(silhouette_score(x__test, y_pred))\n",
    "    \n",
    "    y_pred_t = k_medoid(m_eucli, k)\n",
    "    scores_t.append(silhouette_score(x__test, y_pred_t))\n",
    "    \n",
    "    y_pred_n3 = k_medoid(m_n3, k)\n",
    "    scores_n3.append(silhouette_score(x__test, y_pred_n3))\n",
    "\n",
    "plt.plot(k_range, scores, label='Distance Euclidienne (KMeans)')\n",
    "plt.plot(k_range, scores_t, label='Distance Euclidienne (k-medoide)')\n",
    "plt.plot(k_range, scores_n3, label='Distance n3 (k-medoide)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Score silhouette')\n",
    "plt.title('Score silhouette en fonction de k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme partition binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définie une matrice des distances avec la métrique de notre choix\n",
    "m = pairwise_distances(x__test, metric=metric_n3)\n",
    "\n",
    "\n",
    "\n",
    "scores = []\n",
    "scores_t=[]\n",
    "k_range = range(2,20)\n",
    "for k in k_range:\n",
    "    y_pred = AgglomerativeClustering(affinity='euclidean', linkage='average', n_clusters=k).fit_predict(x__test)\n",
    "    scores.append(silhouette_score(x__test, y_pred))\n",
    "    y_pred_t = AgglomerativeClustering(affinity='precomputed', linkage='average', n_clusters=k).fit_predict(m)\n",
    "    scores_t.append(silhouette_score(x__test, y_pred_t))\n",
    "plt.plot(k_range, scores, label='Distance Euclidienne')\n",
    "plt.plot(k_range, scores_t, label='Distance n3')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Score silhouette')\n",
    "plt.title('Score silhouette en fonction de k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme PCoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestNeighbors, kneighbors_graph,KNeighborsClassifier\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.utils.graph import graph_shortest_path\n",
    "scores = []\n",
    "scores_t=[]\n",
    "k_range = range(2,20)\n",
    "\n",
    "for k in k_range:\n",
    "    #caculer k voisin graphe\n",
    "    kng = kneighbors_graph(x__test,n_neighbors=k, mode='distance',metric=metric_n3)\n",
    "    #caculer le plus court chemin\n",
    "    distmatrix = graph_shortest_path(kng,directed=False,method ='D')\n",
    "    isomap=MDS(n_components=500,dissimilarity='precomputed')\n",
    "    X_transformed = isomap.fit_transform(distmatrix)#isomap avec notre distance propre\n",
    "    print(\"1\")\n",
    "    #isomp avec euclidean\n",
    "    mds=MDS(n_components=500)\n",
    "    X_transformedEuc=mds.fit_transform(x__test)\n",
    "    \n",
    "    \n",
    "    y_pred = KMeans(n_clusters=5).fit_predict( X_transformed )\n",
    "    scores.append(silhouette_score(x__test, y_pred))\n",
    "    \n",
    "    y_pred_t = KMeans(n_clusters=5).fit_predict(X_transformedEuc )\n",
    "    scores_t.append(silhouette_score(x__test, y_pred_t))\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot(k_range, scores, label='Distance propre (isomap)')\n",
    "plt.plot(k_range, scores_t, label='Distance Euclidienne (isomap')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Score silhouette')\n",
    "plt.title('Score silhouette en fonction de k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
